{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "**Make Spark available in Jupyter notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enable access to s3 data from Spark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to be able to read data via S3A we need a couple of dependencies / \n",
    "# we need to make sure the hadoop-aws and aws-java-sdk packages are available when we load spark:\n",
    "\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \"--packages com.amazonaws:aws-java-sdk-pom:1.10.34,org.apache.hadoop:hadoop-aws:3.3.1 pyspark-shell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need the aws credentials in order to be able to access the s3 bucket. \n",
    "# We can use the configparser package to read the credentials from the standard aws file.\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read(os.path.expanduser(\"~/.aws/credentials\"))\n",
    "aws_profile = 'default'\n",
    "access_id = config.get(aws_profile, \"aws_access_key_id\") \n",
    "access_key = config.get(aws_profile, \"aws_secret_access_key\")\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = access_id\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = access_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initiate a spark session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/13 13:10:56 WARN Utils: Your hostname, LAPTOP-87B7CMDN resolves to a loopback address: 127.0.1.1; using 172.27.249.164 instead (on interface eth0)\n",
      "22/01/13 13:10:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/mnt/c/Users/user/Ubuntu/Programs/spark-3.2.0-bin-hadoop3.2/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/mwary/.ivy2/cache\n",
      "The jars for the packages stored in: /home/mwary/.ivy2/jars\n",
      "com.amazonaws#aws-java-sdk-pom added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-4719a0ef-6016-44c6-b6c9-4bbe59ee13d4;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.amazonaws#aws-java-sdk-pom;1.10.34 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.1 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.901 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 290ms :: artifacts dl 7ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.901 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-pom;1.10.34 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.1 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   4   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-4719a0ef-6016-44c6-b6c9-4bbe59ee13d4\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/9ms)\n",
      "22/01/13 13:10:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/13 13:11:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Fruits\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.21.63.180:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Fruits</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f6894df15e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test: reading a piece of data from S3\n",
    "\n",
    "(within S3 bucket: (1) a folder \"Data\" with 2 folders \"Test\" and \"Training\", and (2) a folder \"Sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpath = \"s3a://mw-projet8/Sample/Apricot/3_100.jpg\" # path to a specific image\n",
    "testpath2 = \"s3a://mw-projet8/Sample/Apricot\" # path to a specific Sample folder containing a few images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/04 13:49:55 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    }
   ],
   "source": [
    "image_df = spark.read.format(\"image\").load(testpath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               image|\n",
      "+--------------------+\n",
      "|{s3a://mw-projet8...|\n",
      "|{s3a://mw-projet8...|\n",
      "|{s3a://mw-projet8...|\n",
      "|{s3a://mw-projet8...|\n",
      "|{s3a://mw-projet8...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additionnal librairies to be imported\n",
    "from pyspark.sql.functions import split, udf\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "#from tensorflow.keras.utils import load_img\n",
    "#from keras.preprocessing.image import img_to_array\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On data stored on local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+\n",
      "|               image|                path|    class|\n",
      "+--------------------+--------------------+---------+\n",
      "|{file:///mnt/c/Us...|/mnt/c/Users/user...|Raspberry|\n",
      "|{file:///mnt/c/Us...|/mnt/c/Users/user...|Raspberry|\n",
      "|{file:///mnt/c/Us...|/mnt/c/Users/user...|Raspberry|\n",
      "+--------------------+--------------------+---------+\n",
      "\n",
      "1.3302748203277588\n"
     ]
    }
   ],
   "source": [
    "localtestpath = \"/mnt/c/Users/user/Ubuntu/Projet8/Sample/*\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# loading data\n",
    "local_image_df = spark.read.format(\"image\").load(localtestpath).limit(3).toDF('image') # need to limit the size to run the PCA (RAM)\n",
    "\n",
    "# adding a column with image path\n",
    "local_image_df = local_image_df.withColumn(\"path\", local_image_df.image.origin)\n",
    "local_image_df = local_image_df.withColumn(\"path\", split(local_image_df.path, '//')[1])\n",
    "\n",
    "# adding a column with class\n",
    "local_image_df = local_image_df.withColumn(\"class\", split(local_image_df.path, '/')[8]) # Don't know why, but [-2] returns 'null'\n",
    "\n",
    "\n",
    "local_image_df.show()\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 16:15:54.892235: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-11 16:15:54.892288: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-11 16:15:54.892306: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-87B7CMDN): /proc/driver/nvidia/version does not exist\n",
      "2022-01-11 16:15:54.892571: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 512)              0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# defining model to extract features from images\n",
    "    # Chosen model = VGG16\n",
    "\n",
    "model = VGG16(weights=\"imagenet\", include_top=False, pooling='max', input_shape=(224, 224, 3))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 16:16:25.827796: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://6b4de984-d1ac-4c2e-b77e-e0bf739eaed5/assets\n"
     ]
    }
   ],
   "source": [
    "# broadcasting the model for faster runs\n",
    "sc = spark.sparkContext\n",
    "#sc.broadcast(model) # works with: return Vectors.dense(model.predict(image).ravel().tolist())\n",
    "model_bc = sc.broadcast(model) # works with: return Vectors.dense(model_bc.value.predict(image).ravel().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-11 16:18:06.646394: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-11 16:18:06.646439: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-01-11 16:18:26.685437: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-11 16:18:26.685476: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-11 16:18:26.685489: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-87B7CMDN): /proc/driver/nvidia/version does not exist\n",
      "2022-01-11 16:18:26.685667: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+\n",
      "|                path|    class|            vgg16vec|\n",
      "+--------------------+---------+--------------------+\n",
      "|/mnt/c/Users/user...|Raspberry|[30.6986541748046...|\n",
      "|/mnt/c/Users/user...|Raspberry|[85.2619171142578...|\n",
      "|/mnt/c/Users/user...|Raspberry|[40.4808235168457...|\n",
      "+--------------------+---------+--------------------+\n",
      "\n",
      "24.809859037399292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# extracting image features as vectors, stored in a new column within the df\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def LoadPreprocessFeaturizeKerasVGG16(path):\n",
    "    image = img_to_array(load_img(path, target_size=(224, 224, 3)))\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = preprocess_input(image)\n",
    "    return Vectors.dense(model_bc.value.predict(image).ravel().tolist()) \n",
    "\n",
    "extract_features = udf(lambda x: LoadPreprocessFeaturizeKerasVGG16(x), VectorUDT())\n",
    "\n",
    "local_img_df_feat = local_image_df.withColumn('vgg16vec', extract_features('path')).select('path', 'class', 'vgg16vec')\n",
    "    #alternative:\n",
    "    #local_img_df_feat = local_image_df.select('path', 'class', extract_features('path').alias('vgg16features'))\n",
    "\n",
    "local_img_df_feat.show()\n",
    "local_img_df_feat.persist()\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/11 16:18:58 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/01/11 16:18:58 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/01/11 16:18:58 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "22/01/11 16:18:58 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+\n",
      "|                path|    class|         pcaFeatures|\n",
      "+--------------------+---------+--------------------+\n",
      "|/mnt/c/Users/user...|Raspberry|[23.1685062618692...|\n",
      "|/mnt/c/Users/user...|Raspberry|[-67.201651924885...|\n",
      "|/mnt/c/Users/user...|Raspberry|[259.207172055180...|\n",
      "+--------------------+---------+--------------------+\n",
      "\n",
      "3.8878350257873535\n"
     ]
    }
   ],
   "source": [
    "# performing PCA (https://spark.apache.org/docs/1.5.1/ml-features.html#pca)\n",
    "    # for k=50, \n",
    "    # on full Sample dataset (with previous code run in undistributed manner to enable PCA run --RAM), \n",
    "    # pca_model.explainedVariance showed that k=10 explains 0.9110833438360058 of variance\n",
    "    # cf below\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "pca = PCA(k=10, inputCol=\"vgg16vec\", outputCol=\"pcaFeatures\")\n",
    "pca_model = pca.fit(local_img_df_feat)\n",
    "result = pca_model.transform(local_img_df_feat).select([\"path\", \"class\", \"pcaFeatures\"])\n",
    "result.show()\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 22:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226.18474555015564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# saving spark df as parquet\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "#result.write.parquet(\"/mnt/c/Users/user/Ubuntu/Projet8/Sample/result.parquet\")  # error if file already exists\n",
    "result.write.format(\"parquet\").mode('overwrite').save(\"/mnt/c/Users/user/Ubuntu/Projet8/SampleResult.parquet\")\n",
    "\n",
    "duration = time.time() - start_time\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_==> Extra: PCA explained variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.2934, 0.1748, 0.1244, 0.0849, 0.0649, 0.0435, 0.0347, 0.0319, 0.0303, 0.0283, 0.0239, 0.0211, 0.0187, 0.0157, 0.0094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for k=50\n",
    "#pca_model.explainedVariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.29339395245505906\n",
      "2 : 0.46821396420083106\n",
      "3 : 0.5926431813750801\n",
      "4 : 0.6774965829997943\n",
      "5 : 0.7424071058821711\n",
      "6 : 0.7859508398211603\n",
      "7 : 0.8206208403371235\n",
      "8 : 0.8525010127567214\n",
      "9 : 0.882827138500174\n",
      "10 : 0.9110833438360058\n",
      "11 : 0.9350045396262557\n",
      "12 : 0.9561443217788522\n",
      "13 : 0.9748861674372339\n",
      "14 : 0.9906359038878038\n",
      "15 : 0.9999999999999952\n"
     ]
    }
   ],
   "source": [
    "# for k=50\n",
    "#expvar = 0\n",
    "#for i in range (15):\n",
    "#    expvar += pca_model.explainedVariance[i]\n",
    "#    print(i+1, ':', expvar)\n",
    "\n",
    "# 10 components are enough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On data stored on S3\n",
    "Below code = code run on EC2 instance, without limiting the dataset to 3 rows.\n",
    "\n",
    "https://docs.databricks.com/applications/machine-learning/preprocess-data/transfer-learning-tensorflow.html\n",
    "https://stackoverflow.com/questions/61096573/using-tensorflow-keras-model-in-pyspark-udf-generates-a-pickle-error\n",
    "https://stackoverflow.com/questions/70346484/how-to-limit-tracing-when-doing-transfer-learning-in-pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/13 13:11:46 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- modificationTime: timestamp (nullable = true)\n",
      " |-- length: long (nullable = true)\n",
      " |-- content: binary (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "img_path = \"s3a://mw-projet8/Sample/\"\n",
    "\n",
    "# Reading the sample set in a distributed way as binary files\n",
    "images = spark.read.format(\"binaryFile\")\\\n",
    ".option(\"pathGlobFilter\", \"*.jpg\")\\\n",
    ".option(\"recursiveFileLookup\", \"true\").load(img_path).limit(3).toDF('path', 'modificationTime', 'length', 'content')\n",
    "print(type(images))\n",
    "print(images.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+\n",
      "|                path|             content|    class|\n",
      "+--------------------+--------------------+---------+\n",
      "|s3a://mw-projet8/...|[FF D8 FF E0 00 1...|Raspberry|\n",
      "|s3a://mw-projet8/...|[FF D8 FF E0 00 1...|Raspberry|\n",
      "|s3a://mw-projet8/...|[FF D8 FF E0 00 1...|Raspberry|\n",
      "+--------------------+--------------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "images = images.withColumn(\"class\", split(images.path, '/')[4]).select(['path', 'content', 'class'])\n",
    "images.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-13 13:13:01.518427: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-13 13:13:01.518554: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Necessary libraries for image processing (including #those already imported)\n",
    "\n",
    "# Garbage collector\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "# Useful libraries\n",
    "#import pandas as pd  #already imported\n",
    "#import numpy as np  #already imported\n",
    "import io\n",
    "\n",
    "# ComputerVision tools\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# Spark tools\n",
    "#from pyspark.sql.functions import split, udf  #already imported\n",
    "from pyspark.sql.functions import col, pandas_udf, PandasUDFType\n",
    "#from pyspark.ml.linalg import Vectors, VectorUDT  #already imported\n",
    "#from pyspark.ml.feature import PCA  #already imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16 summary:\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 100, 100, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 100, 100, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 50, 50, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 50, 50, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 50, 50, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 25, 25, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 25, 25, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 25, 25, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 25, 25, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 12, 12, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " global_max_pooling2d_1 (Glo  (None, 512)              0         \n",
      " balMaxPooling2D)                                                \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/user/Ubuntu/Programs/spark-3.2.0-bin-hadoop3.2/python/pyspark/sql/pandas/functions.py:389: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n",
      "2022-01-13 13:15:23.511702: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-13 13:15:23.511741: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-01-13 13:15:43.438808: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-13 13:15:43.438847: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-13 13:15:43.438863: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-87B7CMDN): /proc/driver/nvidia/version does not exist\n",
      "2022-01-13 13:15:43.439027: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+\n",
      "|                path|    class|               feats|\n",
      "+--------------------+---------+--------------------+\n",
      "|s3a://mw-projet8/...|Raspberry|[84.41844, 0.0, 2...|\n",
      "|s3a://mw-projet8/...|Raspberry|[73.287865, 0.0, ...|\n",
      "|s3a://mw-projet8/...|Raspberry|[55.54396, 0.0, 4...|\n",
      "+--------------------+---------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "\n",
    "# Loading the VVG16 model once to get the weights\n",
    "# and check that the top layers are removed\n",
    "model = VGG16(include_top=False, pooling='max', input_shape=(100,100,3))\n",
    "print('VGG16 summary:')\n",
    "print(model.summary())\n",
    "\n",
    "# Broadcasting model weights\n",
    "    # https://stackoverflow.com/questions/61096573/using-tensorflow-keras-model-in-pyspark-udf-generates-a-pickle-error\n",
    "bc_model_weights = sc.broadcast(model.get_weights())\n",
    "del model ; gc.collect()\n",
    "\n",
    "def model_fn():\n",
    "    \"\"\"\n",
    "    Returns a VGG16 model with top layer removed\n",
    "    and broadcasted pretrained weights.\n",
    "    \"\"\"\n",
    "    model = VGG16(weights=None, include_top=False, pooling='max', input_shape=(100,100,3))\n",
    "    model.set_weights(bc_model_weights.value)\n",
    "    return model\n",
    "\n",
    "def preprocess(content):\n",
    "    \"\"\"\n",
    "    Preprocesses raw image bytes for prediction.\n",
    "    \"\"\"\n",
    "    img = Image.open(io.BytesIO(content))\n",
    "    arr = img_to_array(img)\n",
    "    return preprocess_input(arr)\n",
    "\n",
    "def featurize_series(model, content_series):\n",
    "    \"\"\"\n",
    "    Featurizes a pd.Series of raw images using the input model.\n",
    "    :returns: a pd.Series of image features\n",
    "    \"\"\"\n",
    "    input = np.stack(content_series.map(preprocess))\n",
    "    preds = model.predict(input)\n",
    "    # For some layers, output features will be multi-dimensional tensors.\n",
    "    # We flatten the feature tensors to vectors\n",
    "    # for easier storage in Spark DataFrames.\n",
    "    output = [p.flatten() for p in preds] # not necessary with ``pooling='max'`` for VGG16\n",
    "    return pd.Series(output)\n",
    "\n",
    "@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\n",
    "def featurize_udf(content_series_iter):\n",
    "    '''\n",
    "    This method is a Scalar Iterator pandas UDF\n",
    "    wrapping our featurization function.\n",
    "    The decorator specifies that this returns a Spark DataFrame column\n",
    "    of type ArrayType(FloatType).\n",
    "\n",
    "    :param content_series_iter: This argument is an iterator\n",
    "                                over batches of data, where each batch\n",
    "                                is a pandas Series of image data.\n",
    "    '''\n",
    "    # With Scalar Iterator pandas UDFs, we can load the model once\n",
    "    # and then re-use it for multiple data batches.\n",
    "    # This amortizes the overhead of loading big models.\n",
    "    model = model_fn()\n",
    "    for content_series in content_series_iter:\n",
    "        yield featurize_series(model, content_series)\n",
    "\n",
    "df = images.select(col(\"path\"), col(\"class\"), featurize_udf(\"content\").alias(\"feats\"))\n",
    "df.show()\n",
    "\n",
    "# adding a persist() step\n",
    "df.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+\n",
      "|                path|    class|            vecfeats|\n",
      "+--------------------+---------+--------------------+\n",
      "|s3a://mw-projet8/...|Raspberry|[84.4184417724609...|\n",
      "|s3a://mw-projet8/...|Raspberry|[73.2878646850586...|\n",
      "|s3a://mw-projet8/...|Raspberry|[55.5439605712890...|\n",
      "+--------------------+---------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# vectorizing features - i.e. requirement for PCA\n",
    "\n",
    "vectorize_features = udf(lambda x: Vectors.dense(x), VectorUDT())\n",
    "\n",
    "df = df.select(col(\"path\"), col(\"class\"), vectorize_features(\"feats\").alias(\"vecfeats\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f056c25d8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f056c1e6e50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "22/01/13 13:16:20 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/01/13 13:16:20 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/01/13 13:16:21 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "22/01/13 13:16:21 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n",
      "[Stage 20:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+\n",
      "|                path|    class|            pcaFeats|\n",
      "+--------------------+---------+--------------------+\n",
      "|s3a://mw-projet8/...|Raspberry|[53.5481247404085...|\n",
      "|s3a://mw-projet8/...|Raspberry|[335.795156953732...|\n",
      "|s3a://mw-projet8/...|Raspberry|[104.780163123623...|\n",
      "+--------------------+---------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# performing PCA (https://spark.apache.org/docs/1.5.1/ml-features.html#pca)\n",
    "    # with k=10 --> ca. 91% of variance explained - cf above\n",
    "\n",
    "pca = PCA(k=10, inputCol=\"vecfeats\", outputCol=\"pcaFeats\")\n",
    "pca_model = pca.fit(df)\n",
    "result = pca_model.transform(df).select([\"path\", \"class\", \"pcaFeats\"])\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-13 13:22:17.931409: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-13 13:22:17.931818: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-01-13 13:22:38.849706: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-13 13:22:38.849847: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-13 13:22:38.850279: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-87B7CMDN): /proc/driver/nvidia/version does not exist\n",
      "2022-01-13 13:22:38.850868: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "22/01/15 00:53:48 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 393391 ms exceeds timeout 120000 ms\n",
      "22/01/15 00:53:48 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "# saving spark df 'result' as parquet\n",
    "\n",
    "#result.write.parquet(\"/mnt/c/Users/user/Ubuntu/Projet8/Sample/result.parquet\")  # error if file already exists\n",
    "result.write.format(\"parquet\").mode('overwrite').save(\"s3a://mw-projet8/SampleResult.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p8venv",
   "language": "python",
   "name": "p8venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
